dropout: 0.1
lr: 2.0e-05
model_name: tohoku-nlp/bert-base-japanese-whole-word-masking
num_labels: 8
total_steps: 6190
warmup_steps: 619
weight_decay: 0.1
