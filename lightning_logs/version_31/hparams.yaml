dropout: 0.1
lr: 8.0e-05
model_name: tohoku-nlp/bert-base-japanese-whole-word-masking
num_labels: 8
total_steps: 1322.5
warmup_steps: 132
weight_decay: 0.1
