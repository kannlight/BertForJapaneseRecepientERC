dropout: 0.1
lr: 0.0001
model_name: tohoku-nlp/bert-base-japanese-whole-word-masking
num_labels: 8
total_steps: 1550
warmup_steps: 155
weight_decay: 0.1
