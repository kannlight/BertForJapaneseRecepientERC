lr: 0.0001
model_name: tohoku-nlp/bert-base-japanese-whole-word-masking
num_labels: 8
